# Round1-3-16-2025
ScriptChain Health the first interview for the ML internship position
Q1: Suppose that we design a deep architecture to represent a sequence by stacking self-attention layers with positional encoding. What could be the issues? (paragraph format)
Stacking self-attention layers with positional encoding can introduce several challenges. First, vanishing positional information may occur in deep architectures: positional encodings are typically added once at the input layer, and their influence might diminish as signals propagate through multiple layers. This is exacerbated if residual connections or layer normalization are improperly tuned. Second, computational complexity grows quadratically with sequence length due to the self-attention mechanism, making deep architectures resource-intensive for long sequences. Third, over-smoothing—a phenomenon where token representations become indistinguishable after repeated transformations—can reduce the model’s ability to capture fine-grained positional relationships. Additionally, fixed positional encodings (e.g., sinusoidal) might not adapt well to varying sequence lengths or domain-specific patterns. Learnable positional embeddings could mitigate this but require careful initialization and regularization to avoid overfitting. Finally, gradient instability in deep networks may hinder training unless techniques, like skip connections or gradient clipping, are employed.

Q2: Can you design a learnable positional encoding method using Pytorch? (Create a dummy dataset)
Video Link: https://drive.google.com/file/d/1L-hzzM9tMVPXR39CXbS_FmzsgJnTAihA/view?usp=sharing
